{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50fc5be",
   "metadata": {},
   "source": [
    "# Data Ingestion and Threshold-Based Anomaly Labeling\n",
    "---\n",
    "* Load the dataset from CSV into a Pandas DataFrame.\n",
    "* Define error margin and quantiles for CPU, RAM, and Disk.\n",
    "* Compute thresholds for each metric using the specified quantiles, adding the error margin to RAM and Disk.\n",
    "* Print the computed thresholds as percentages.\n",
    "* Store thresholds in a dictionary for easy reference.\n",
    "* Apply rule-based classification: label as `1` (anomaly) if any metric exceeds its threshold, otherwise `0` (normal).\n",
    "* Print counts of predicted labels (`0` vs `1`).\n",
    "* Print percentages of predicted labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a32ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Thresholds: \n",
      "CPU: 71.40%\n",
      "RAM: 74.82%\n",
      "DISK:60.15%\n",
      "------------------------------------------------------------\n",
      "Label counts:\n",
      "pred_label\n",
      "0    3192\n",
      "1     422\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------\n",
      "\n",
      "Label percentages:\n",
      "pred_label\n",
      "0    88.323188\n",
      "1    11.676812\n",
      "Name: proportion, dtype: float64\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Data/system_metrics_binary.csv')\n",
    "\n",
    "error = 0.1\n",
    "\n",
    "cpu_quantile = 0.925\n",
    "ram_quantile = 0.9\n",
    "disk_quantile = 0.85\n",
    "\n",
    "thresholds = {\n",
    "    \"cpu\": df[\"cpu_ratio\"].quantile(cpu_quantile),\n",
    "    \"ram\": df[\"ram_ratio\"].quantile(ram_quantile)+error,\n",
    "    \"disk\": df[\"disk_ratio\"].quantile(disk_quantile)+error\n",
    "}\n",
    "print('----'*15)\n",
    "print(f\"Thresholds: \\nCPU: {thresholds['cpu']*100:.2f}%\\nRAM: {thresholds['ram']*100:.2f}%\\nDISK:{thresholds['disk']*100:.2f}%\")\n",
    "print('----'*15)\n",
    "# Your computed thresholds\n",
    "THRESHOLDS = {\n",
    "    \"cpu\": thresholds['cpu'],\n",
    "    \"ram\": thresholds['ram'],\n",
    "    \"disk\": thresholds['disk']\n",
    "}\n",
    "\n",
    "\n",
    "# Apply rule-based classification\n",
    "df[\"pred_label\"] = (\n",
    "    (df[\"cpu_ratio\"] > THRESHOLDS[\"cpu\"]) |\n",
    "    (df[\"ram_ratio\"] > THRESHOLDS[\"ram\"]) |\n",
    "    (df[\"disk_ratio\"] > THRESHOLDS[\"disk\"])\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# Show counts\n",
    "print(\"Label counts:\")\n",
    "print(df[\"pred_label\"].value_counts())\n",
    "print('----'*15)\n",
    "\n",
    "print(\"\\nLabel percentages:\")\n",
    "print(df[\"pred_label\"].value_counts(normalize=True) * 100)\n",
    "print('----'*15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e073d",
   "metadata": {},
   "source": [
    "# Checking Label Counts\n",
    "---\n",
    "\n",
    "- Verifying Class Imabalance before Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba56808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "pred_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "51fe8c4e-168e-40b9-9e6c-fb1eaef3dcca",
       "rows": [
        [
         "0",
         "3018"
        ],
        [
         "1",
         "399"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "pred_label\n",
       "0    3018\n",
       "1     399\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pred_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac02e9",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "---\n",
    "1. Label Encoding the Target Column\n",
    "2. Splitting between Train and Test Data \n",
    "3. Creating a Preprocessing Pipline for the Data with the Following Steps:\n",
    "    > 1. A Column Transformer that Scales the Numeric Data\n",
    "    > 2. Adding to the Main Pipeline where the Class Imbalance in the Data is Handled through SMOTE\n",
    "    > 3. Finishing it off with a Placeholder Model for Grid Search CV and Hyper Parameter Tuning\n",
    "4. This Pipeline is designed for Evaluating Supervised Machine Learning Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"cpu_ratio\", \"ram_ratio\", \"disk_ratio\"]\n",
    "X = df[features]\n",
    "y = df['pred_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b7256bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a14422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# PREPROCESSING\n",
    "# =========================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), features),]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# PIPELINE (CLASSIFIER IS SWAPPED)\n",
    "# =========================\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", LogisticRegression())  # placeholder\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e56be",
   "metadata": {},
   "source": [
    "# Supervised Model Evaluation\n",
    "---\n",
    "\n",
    "### **Models Selected:**\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifier\n",
    "3. Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75fa8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PARAMETER GRID (MULTI-MODEL)\n",
    "# =========================\n",
    "param_grid = [\n",
    "\n",
    "    # ---- Logistic Regression ----\n",
    "    {\n",
    "        \"clf\": [LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            solver=\"liblinear\"\n",
    "        )],\n",
    "        \"clf__C\": [0.1, 1.0, 10.0],\n",
    "    },\n",
    "\n",
    "    # ---- Random Forest ----\n",
    "    {\n",
    "        \"clf\": [RandomForestClassifier(\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 10, 20],\n",
    "        \"clf__min_samples_split\": [2, 5],\n",
    "    },\n",
    "\n",
    "    # ---- Gradient Boosting ----\n",
    "    {\n",
    "        \"clf\": [GradientBoostingClassifier(\n",
    "            random_state=42\n",
    "        )],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__learning_rate\": [0.05, 0.1],\n",
    "        \"clf__max_depth\": [3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# GRID SEARCH CV\n",
    "# =========================\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87c3fa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 23 candidates, totalling 115 fits\n",
      "\n",
      "Best model:\n",
      "RandomForestClassifier(n_jobs=-1, random_state=42)\n",
      "\n",
      "Best parameters:\n",
      "{'clf': RandomForestClassifier(n_jobs=-1, random_state=42), 'clf__max_depth': None, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[604   0]\n",
      " [  0  80]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       604\n",
      "           1       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00       684\n",
      "   macro avg       1.00      1.00      1.00       684\n",
      "weighted avg       1.00      1.00      1.00       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# TRAIN (CV RUNS HERE)\n",
    "# =========================\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# BEST MODEL\n",
    "# =========================\n",
    "print(\"\\nBest model:\")\n",
    "print(grid.best_estimator_[\"clf\"])\n",
    "\n",
    "print(\"\\nBest parameters:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# =========================\n",
    "# FINAL EVALUATION\n",
    "# =========================\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d26e51",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The Random Forest Classifier Performed the best in terms of accuracy, recall and f1 score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e2530",
   "metadata": {},
   "source": [
    "# Unsupervised Model Evaluation\n",
    "--- \n",
    "\n",
    "### **Models Selected:**\n",
    "\n",
    "1. Isolation Forest\n",
    "2. Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75387960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: IsolationForest(contamination=0.1, random_state=42)\n",
      "Best parameters: {'clf': IsolationForest(random_state=42), 'clf__contamination': 0.1, 'clf__max_features': 1.0, 'clf__max_samples': 'auto', 'clf__n_estimators': 100}\n",
      "\n",
      "Confusion Matrix:\n",
      " [[587  17]\n",
      " [ 28  52]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       604\n",
      "           1       0.75      0.65      0.70        80\n",
      "\n",
      "    accuracy                           0.93       684\n",
      "   macro avg       0.85      0.81      0.83       684\n",
      "weighted avg       0.93      0.93      0.93       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"clf\", IsolationForest(random_state=42))  # placeholder\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# PARAMETER GRID\n",
    "# =========================\n",
    "param_grid = [\n",
    "    # Isolation Forest\n",
    "    {\n",
    "        \"clf\": [IsolationForest(random_state=42)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_samples\": [\"auto\", 0.8],\n",
    "        \"clf__contamination\": [0.1, 0.2],\n",
    "        \"clf__max_features\": [1.0, 0.8]\n",
    "    },\n",
    "    # Local Outlier Factor (novelty=True to allow predict)\n",
    "    {\n",
    "        \"clf\": [LocalOutlierFactor(novelty=True)],\n",
    "        \"clf__n_neighbors\": [20, 35],\n",
    "        \"clf__algorithm\": [\"auto\"],\n",
    "        \"clf__leaf_size\": [30, 50],\n",
    "        \"clf__contamination\": [0.1, 0.2]\n",
    "    }\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# GRID SEARCH CV\n",
    "# =========================\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit using training set (labels only for scoring)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# BEST MODEL\n",
    "# =========================\n",
    "best_model_unsupervised = grid.best_estimator_\n",
    "y_pred = best_model_unsupervised.predict(X_test)\n",
    "\n",
    "# Convert -1 anomaly to 1, inliers to 0\n",
    "y_pred = (y_pred == -1).astype(int)\n",
    "\n",
    "print(\"\\nBest model:\", best_model_unsupervised[\"clf\"])\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec70e41",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The Isolation Forest Model performed the best in the unsupervised category but still didn't meet the requirements\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd4096",
   "metadata": {},
   "source": [
    "# Final Verdict:\n",
    "---\n",
    "\n",
    "- The Supervised Models were bettter able to Generalize with the Data\n",
    "- The Unsupervised Models were unable to Generalize with the Data\n",
    "- Therefore, supervised models will be used in the final deployment\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ca885",
   "metadata": {},
   "source": [
    "## Saving the Best Model with the Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60b16767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Client_Projects/dcml2526/models/supervised_best_params_simple.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Saving the best trained pipeline\n",
    "joblib.dump(best_model, \"D:/Client_Projects/dcml2526/models/supervised_pipeline_simple.joblib\")\n",
    "\n",
    "# Saving the best hyperparameters separately\n",
    "joblib.dump(grid.best_params_, \"D:/Client_Projects/dcml2526/models/supervised_best_params_simple.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d3c882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Client_Projects/dcml2526/models/unsupervised_best_params_simple.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model_unsupervised, 'D:/Client_Projects/dcml2526/models/unsupervised_pipeline_simple.joblib')\n",
    "joblib.dump(grid.best_params_, 'D:/Client_Projects/dcml2526/models/unsupervised_best_params_simple.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
